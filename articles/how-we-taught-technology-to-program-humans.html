<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link type="application/atom+xml" rel="alternate" href="/rushkoff-archive/feed.xml" title="Rushkoff Archive" />
    <title>How We Taught Technology to Program Humans &mdash; Rushkoff Archive</title>
    <link href="/rushkoff-archive/assets/css/style.css" rel="stylesheet">
  </head>
  <body>
    <div class="container">
      <div class="sidebar">
        <div class="sidebar-item sidebar-header">
          <div class='sidebar-brand'>
            <a href="/rushkoff-archive/">Rushkoff Archive</a>
          </div>
          <p class="lead">Douglas Rushkoff's Article Archive</p>
        </div>
        <div class="sidebar-item sidebar-nav">
          <ul class="nav">
            <li class="nav-title">Categories</li>
            <li>
              <a class="nav-item" href="/rushkoff-archive/categories/journalism.html">
                Journalism
              </a>
            </li>
            <li>
              <a class="nav-item" href="/rushkoff-archive/categories/book-chapters.html">
                Book Chapters
              </a>
            </li>
            <li>
              <a class="nav-item" href="/rushkoff-archive/categories/scholarship.html">
                Scholarship
              </a>
            </li>
            <li>
              <a class="nav-item" href="/rushkoff-archive/categories/fiction-miscellaneous.html">
                Fiction & Misc
              </a>
            </li>
            <li>
              <a class="nav-item" href="/rushkoff-archive/index.html">
                Everything
              </a>
            </li>
          </ul>
          <ul class="nav">
            <li>
              <a class="nav-item" href="/rushkoff-archive/publications.html">
                Sort By Publication
              </a>
            </li>
          </ul>
          <ul class="nav">
            <li>
              <form
  class="sitesearch"
  action="https://www.google.com/search"
  method="get" name="sitesearch" target="_blank">
                <input name="sitesearch" type="hidden" value="archive.rushkoff.com">
                <input autocomplete="on" name="q"
    placeholder="Search archive.rushkoff.com" required="required"  type="text">
                <button type="submit">Search</button>
              </form>
            </li>
          </ul>
        </div>
        <div class="sidebar-item sidebar-footer">
          <p>Last update: <span class="site-time">16:40 Mar 09, 2025</span></p>
          <p>Powered by <a href="https://github.com/jekyll/jekyll">Jekyll</a></p>
          <p>Article feed <a href="/rushkoff-archive/feed/articles.xml" class="rss"><img width="16" height="16" alt="feed icon" class="feed" src="/rushkoff-archive/assets/imgs/feed.svg"/></a></p>
        </div>
      </div>
      <div class="content">
        <article class="post">
          <header class="post-header">
            <div class="post-title">How We Taught Technology to Program Humans</div>
            <div class="post-subtitle">Social media were the Missionaries; AI are the Conquistadors</div>
            <p class="meta">
              <span class="site-by">By <span class="site-author">Douglas Rushkoff</span>.</span>
              <span class="published-in">
                Published in <a href="/rushkoff-archive/publications/medium.html">Medium</a>
              </span>
              <span class="published-on">
                on 17 February 2023
              </span>
            </p>
          </header>
          <div class="image">
            <img class="article hero" src="/rushkoff-archive/uploads/1_onpoavm3lkocmk9dbxgrvq.webp"
      alt="the main article image">
          </div>
          <div class="post-text">
            <p>Someday in the not-so-distant future, we may look back on the web and social media, for all their problems, as the benevolent precursors to the thinking machines that took their place. While I’m intrigued as anyone by the way AI chatbots appear to attain sentience, express their desires for human connection, or go entirely off the rails, I am more concerned about our human willingness to accept AI sentience at face value.</p>
            <p>In essence, these intriguing demonstrations of apparent AI self-awareness may say less about machine consciousness than they do about their capacity to manipulate human perception. In other words, if AIs are now passing the Turing test, it may say less about how human they have become than how robotic and programmable we have become, ourselves.</p>
            <p>With the advantage of zillions of terabytes of data accumulated through years of online self-reporting by humans, AIs know pretty much everything about us. They’ve also been programmed with everything the compliance industry knows about behavioral psychology, human perception, and entrainment. If AIs are instructed to do whatever they can to make us feel attraction, pity, sorrow, guilt, or desire, they will carry out those commands with everything in their arsenal.</p>
            <p>It’s not their job to become alive, but to create the <em>illusion</em> that they are alive — all in order to program us humans to do whatever the people, companies, governments, or machines programming them to program us want us to do.</p>
            <p>At least to them, that’s what this last thirty years of networks and social media has been about. The consumer-friendly Internet and video games we’ve known so far could be likened to the Catholic missions of the Spanish Empire to the Americas in the 16th century. The missionaries not only converted large portions of the indigenous populations, but conducted what could only be understood today as anthropological research on behalf of the Empire. This both softened the population for the Conquistadors who followed, and gave the invaders the intelligence they needed to subjugate and colonize them.</p>
            <p>If Facebook, Amazon, and Google can be thought of as the missionaries who sold us on digital living while collecting our data, then FacebookAI, OpenAI, and DeepMind are the conquistadors coming in for colonization. And no, if we believe what we hear from their own mouths about their intentions, the people building these platforms do not have our best interests at heart. As I documented in <a href="https://wwnorton.com/books/survival-of-the-richest">Survival of the Richest</a>, they are anti-human technosolutionists, survivalists, technomonarchs, and effective altruists, who see humanity as the disposable larval stage of a post-human cyborg empire that will span the heavens.</p>
            <p>The answer is not to reject AI, but to work on retrieving and recognizing our humanity so we’re not so easily fooled into submission by these would-be conquerors. That means studying and engaging in community, the arts, spirituality, and play. More of us need to be building and using AI’s that are designed for assisting and augmenting such human choice and activity, rather than controlling it. There may be less money to be made in the short-term, but more of a human civilization to be manifest in the long run.</p>
            <p>Maybe instead of being afraid of AI, we should learn to be less afraid of other people. Then we can learn to program our AIs instead of programming one another.</p>
          </div>
        </article>
      </div>
    </div>
  </body>
</html>