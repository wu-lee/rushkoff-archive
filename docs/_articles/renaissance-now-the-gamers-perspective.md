---
publication: _publications/handbook-of-computer-game-studies.md
title: Renaissance Now! The Gamers’ Perspective
subtitle: ''
image: ''
date: 2005-01-01 00:00:00 -0500
blurb: ''
notes: Based on scan from Unified Field Summit
refs: ''
sources: ''
published: false

---
The frightening news is that we are living in a story. The reassuring part is that it's a story we re writing, ourselves.

Alas, though, most of us don't even know it--or are afraid to accept it. Never before did we have so much access to the tools of storytelling--yet few of us are willing to participate in their creation. Gamers might be today's most likely candidates to helm what I hope will be a renaissance in our relationship to stories as well as the reality they mean to describe and influence.

We are living in a world of stories. We can't help but use narratives to understand the events that occur around us. The unpredictability of nature, emotions, social interactions and power relationships led human beings, from prehistoric times, to develop narratives that described the patterns underlying the movements of these forces. Although we like to believe that primitive people actually believed the myths they created about everything from the weather to the afterlife, a growing camp of religious historians are coming to the conclusion that early religions were understood much more metaphorically than we understand religion, today. They didn't believe that the wind or rain were gods; they invented characters whose personalities reflected the properties of these elements. The characters and their stories served more as ways of remembering that it would be cold for four months before spring returns, than genuinely accepted explanations. The people were quite self-consciously and actively anthropomorphizing the forces of nature.

As different people and groups competed for authority, they used their narratives quite differently. They used their stories to gain advantage. Stories were no longer being used simply to predict the patterns of nature, but to describe and influence the courses of politics, economics, and power. In such a world, stories compete solely on the basis of their ability to win believers. To be understood as real. When the Pharaoh or King is treated as if he were a god, it means his subjects are still actively participating in the sham. He still needs to prove his potency, in real ways, at regular intervals. But if the ruler can somehow get his followers to accept the story of his divine authority as historical fact, then he need prove nothing. The story itself serves as a substitute for reality.

Since Biblical times, we have been living in a world where the stories we use to describe and predict our reality have been presented as truth and mistaken for fact. These narratives, and their tellers, compete for believers in two ways: through the content of the stories, and through the medium or tools through which the stories are told. The content of a story might be considered the "what," where the technology through which the story is transmitted can be considered the "how." A story can vie for believers in both ways--through the narrative itself, or by changing the level of the playing field on which it is competing.

Exclusive access to the "how" of storytelling lets a storyteller monopolize the "what." In ancient times, people were captivated by the epic storyteller as much for his ability to remember thousands of lines of text as for the actual content of the Iliad or Odyssey. Likewise, a television program or commercial holds us in its spell as much through the magic of broadcasting technology as its teleplay. Whoever has power to get Inside that magic box has the power to write the story we end up believing.

After all, we don't call the stuff on television "programming" for nothing. The people making teleevision are not programming our TV sets or their evening schedules; they are programming us. We use the dial to select which program we are going to receive, and then we submit to it. This is not so dangerous in itself, but, the less control we have over exactly what is fed to us through the tube, the more vulnerable we are to the whims of our programmers.

For most of us, what goes on in the television set is magic. Before the age of VCRs and camcorders, it was even more so. A television program is a magic act. Whoever has gotten his image in that box must be special. Back in the 1960's, Walter Cronkite used to end his newscast with the assertion, "and that's the way it is." It was his ability to appear in the magic box that gave him the tremendous authority necessary to lay claim to the absolute truth.

I have always recoiled when this rhetorical advantage is exploited by those who have the power to monopolize a medium. Back in college, I remember being incensed by a scene in the third Star Wars movie, Return of the Jedi. Luke and Hans Solo have landed on an alien moon, and are taken prisoner by a tribe of little furry creatures called Ewoks. In an effort to win their liberation, Luke's two robots tell the Ewoks the story of their heroes' struggle against the dark forces of the Empire. C3PO, the golden android, relates the tale, while little R2D2 projects holographic images of battling spaceships. The Ewoks are dazzled by R2's special effects and engrossed in C3PO's tale. The "how" and the "what." They are so moved by the story, that they not only release their prisoners, but fight a violent war on their behalf! I kept wondering, what if Darth Vader had gotten down to the alien moon first, and told his side of the story complete with his own special effects?

Similarly, television programming, like the many one-way media before it, communicates through stories, and it influences us through its seemingly magical capabilities. The programmer creates a character we like--with whom we can identify. As a series of plot developments bring that character into some kind of danger, we follow him, and a sense of tension rises within us.

This is what Aristotle, in his role as one of the first theater analysts, called the rising arc of dramatic action. The storyteller brings the character, and his audience, into as much danger as we can tolerate before inventing his solution--the rescue--allowing us all to let out a big sigh of relief. Back in Aristotle's day, this solution was called _Deus ex machina_ (God from the machine) and one of the Greek gods would descend on a mechanism from the rafters and save the day. In an Arnold Schwarzenegger movie, that miraculous solution might take the form of a new, super-powered laser gun. In a commercial, well, it's the product being advertised. In any case, if he's got a captive audience, the storyteller can pick whichever solution he wants and, if we've been following the story into increasing anxiety, we'll take it.

TV commercials honed this storytelling technique into the perfect 30-second package. A man is at work. His wife calls to tell him she's crashed the car. The boss comes in to tell him he just lost a big account. His bank statement shows he's in the red. His secretary quits. Now his head hurts. We've followed the poor shlub all this way, and we feel his pain. What can he do? He opens the top desk drawer and finds his bottle of Brand A Pain Reliever! He swallows the pills as an awe-inspiring hi-tech animation demonstrates to us the way the pill passes through his body, relieving his pain.

In a passive and mysterious medium, when we are brought into a state of vicarious tension, the storyteller can make swallow any pill he chooses. Only by accepting his solution can we be freed from our despair.

Interactive media changed this equation. Imagine if your grandfather were watching that aspirin commercial back in 1955 on his old console television Even if he suspected that he were watching a commercial designed to put him in a state of anxiety, in order to change the channel and remove himself from the externally imposed tension, he would have to move the popcorn off his lap, pull up the lever on his recliner, walk up to the television set, and manually turn the dial. That's a somewhat rebellious action for a bleary-eyed television viewer. To sit through the rest of the commercial, however harrowing, might cost him only a tiny quantity of human energy until the pills come out of the drawer. The brain, being lazy, chooses the path of least resistance, and grandpa sits through the whole commercial.

Flash forward to 1990. A kid with a remote control In his hand makes the same mental calculation: an ounce of stress, or an infinitesimally small quantity of human effort to move his finger an eighth of an inch and he's free! The remote control gives viewers to power to remove themselves from the storyteller's spell, with almost no effort. Watch a kid--or yourself--the next time he "channel surfs" from program to program. He's not changing the channel because he's bored. He surfs away when he senses that he's being put into an imposed state of tension.

The remote control breaks down the "what." It allows a viewer to deconstruct the content of television media, and avoid failing into the programmer's spell. If he does get back around the dial to watch the end of a program, he no longer has the same captivated orientation. Kids with remotes aren't watching television they are watching the television, playing television. Putting it through its paces.

Just as the remote control allowed a generation to deconstruct the content of television, the videogame joystick demystified its technology. Remember back to the first time you ever saw a videogame. It was probably "Pong," that primitive black and white depiction of a ping pong table, with a square on either side of the screen representing the paddle, and a tiny white dot representing the ball. Now, remember the exhilaration you felt at playing that game for the very first time. Was it because you had always wanted an effective simulation of ping pong? Did you celebrate because you'd be able to practice without purchasing an entire table and installing it in the basement? Of course not. You were celebrating the simple ability to be able to move the pixels on the screen for the first time. It was a moment of revolution! The screen was no longer the exclusive turf of the television broadcasters. Thanks to the joystick, as well as the subsequent introduction of the VCR and camcorder, we were empowered to move the pixels ourselves. The TV was no longer magical. Its functioning had become transparent.

Finally, the computer mouse and keyboard transformed a receive-only monitor into a portal. Packaged programming was no longer any more valuable--or valid--than the words we could type ourselves. The addition of a modem turned the computer into a broadcast facility. We were no longer dependent on the content of Rupert Murdoch or CBS, but could create and disseminate our own. The Internet revolution was a "do-it-yourself" or DIY revolution. The people were now the content. New forms of community were being formed.

Of course this represented a tremendous threat to business as usual. Studies in the mid-

1990's showed that families with Internet-capable computers were watching an average

of nine hours less television per week. What's worse, Internet enthusiasts were sharing

information, ideas, and even whole computer programs, for !reel Software known as

'freeware' and "shareware" gave rise to a gttt economy based on community and mutual

sett-interest. People were turning to alternative news and entertainment sources for

which they didn1 have to pay-,md, worse, they were watching fewer commercials.

Something had to be done. And it was.

Through a series of both deliberate and utterly systemic responses to the threat of

interactivity, the mainstream media sought to reverse the effects of the remote, the

joystick, and the mouse. Borrowing a term from 1970's social science, media business

advocates declared that we were now living in an 'attention economy.• True enough, the

mediaspace might be infinite, but there are only so many hours in a _day during which

potential audience members might be viewing a program. These units of human time

became known as "eyeball-hours," and pains were taken to create TV shows and web

sites "sticky" enough to engage those eyeballs long enough to show them an

advertisement. Perhaps coincidentally, the growth of the attention economy was

accompanied by an increase of concern over the "attention spans" of young people.

Channel surfing and similar behavior became equated with a very real but differently

diagnosed childhood illness called Attention Deficit Disorder. Children who refused to

pay attention were much too quickly drugged, before the real reasons for their

adaptation to the onslaught of commercial messages were even considered.

The demystification of media enabled by the joystick and other tools was quickly

· reversed through the development of increasingly opaque computer interfaces. While an

early DOS computer user tended to understand a lot about how his computer stored

information and launched programs, later operating systems such as Windows 95 put

more barriers in place. Although these operating systems make computers easier to use

in certain ways, they prevent users from gaining access or command over its more

intricate processes. Now, to install a new program, users must consult "the wizard."

What better metaphor do we need for the remystttication of the computer? As a result,

"computer literacy" no longer means being able to program a computer, but merely

knowing how to use Microsoft Office.

Finally, the DIY ethic of the Internet community was replaced by the new value of

commerce. The communications age was re branded as an "information age,• even

though the Internet had never really been about downloading files or data, but, instead,

about communicating with other people. The difference was that information, or

"content," unlike real human interaction, could be bought and sold. It is a commodity.

When selling information online didn't work, businesspeople turned to selling real

products onhne. Thus, the e-commerce boom was ignited. Soon the internet became the

World Wide Web, whose opaque and image-heavy interfaces made it increasingly one-

way