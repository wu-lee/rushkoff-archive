---
publication: _publications/when-things-learn.md
title: Learning a Few Things
subtitle: ''
image: ''
date: 2002-04-15T00:00:00.000-04:00
blurb: ''
notes: Unknown publication date. Date used is from Dropbox, which was the source for
  this article.
refs: ''
sources: ''
categories:
- _categories/book-chapters.md

---
Things don’t learn. They can’t. That’s why we call them “things.” Or at least that’s how I’ve always felt most comfortable musing about the intelligence of inorganic matter. That is, until I fully considered the concepts being bandied about by the scientists in this book.

My interest in technology has always leaned toward the fantastical. The first time I posted to a FIDO-NET bulletin board or threw on a pair of primitive VR goggles was like being transported into a different world. It was an alternative universe, where the limitless possibilities of a vision quest or lucid dream were now suddenly on tap.

But somehow, because of my own naïve understanding of how these technologies actually worked, I was able to keep my experience of the technological relegated to the distant sphere of mystic journey or spiritual discovery. These tools might extend one’s ability to participate the Gaian mind, but they certainly wouldn’t achieve any lifelike dimensionality of their own. Why, that would challenge the notion that we thinking creatures are somehow special. The cyborg archetype always had a person inside.

But that was a different era.

See, back in the 1980’s, when writers and artists like me got interested in the sudden explosion of new technologies, most of the real scientists were too busy actually figuring stuff out to sit around and muse on the possibilities of virtual reality, tele-robotics, cyberspace, or nano-technology. Instead, the responsibility for pondering the implications of these developments fell on us, the under-qualified poets and novelists. Romantic as we were, we always placed the human imagination above technological reality – and succeeded in vastly underestimating the true potential of the toys with which we were playing.

What a relief it is that Razorfish has decided to create opportunities for some real scientists do the talking for a change. Reading their uncensored, unrehearsed, and uninhibited conversations is at once refreshing yet terrifying, reassuring yet humbling. You hold in your hand a set of deeply informed reflections on technology’s evolution towards something akin to human reason.

Scientists to the core, these people spend a good deal of time coming to consensus about just what it is they’re discussing. And rather than simply ignoring the facts and plot points that might hurt their assertions or story lines, they mine these inconsistencies for new paths of inquiry. Paradoxes are not treated as stumbling blocks, but as opportunities.

So let’s dispense for a moment with our ingrained sense of God’s good order, and suppose, along with these ladies and gentlemen, that science may one day soon actually develop a machine that can not only think, but learn.

Sure enough, it becomes easy to consider how almost everything learns in one way or another. Even a rubber band stretched around a book for too long “learns” by losing its elasticity, and “remembering” the shape of the object to which it was wed for so long.

But no, this isn’t really learning, at least not according to the voices here – it’s merely reacting. Real learning involves solving new problems using the experience of old ones. Today’s most readily available examples might be digital video recorders like Tevo that study our viewing patterns and then record for us the shows we tend to like. Or cars that observe our driving habits, and then change their suspension and gear-shifting to optimum parameters for our individual styles.

When they talk about it that way, I don’t worry so much about the ways in which things might learn. It’s not as if our machines are becoming alive – they’re just learning how to serve us better, without our spelling everything out for them.

But the romantic in me is still troubled. It’s easy to limit one’s consideration of technologies “learning” to the simple case of machines coming to understand what I, as a consumer or computer user, want. Which TV shows I want to watch, which books I want to buy, how I want to drive my car. Tevo might as well be a dog or a slave. It simply learns how to do its master’s bidding. So is this really learning?

I’m not so sure. Maybe that’s why other programmers are working on ways to make machines appear to be more sentient than they really are. New computer interfaces simulate the process of thinking by asking questions they already know the answers to, or pretending to make small mistakes. Again, though, these are pre-determined idiosyncrasies, and not real behaviors. But, then again, why do human beings make mistakes?

The men and women who assembled in Tarrytown traveled through just such difficult terrain, and then some. For example, they focused on how things that learn might be able to impact our own human decision-making capabilities, in real time. One participant called this breed of intelligent device a “contextualizer.” Think of it like a global positioning satellite, but for information, ideas, or even ethics. Perhaps they could take the form of simple memory extensions, as Joy Mountford suggested: a pair of earrings that whispered to her the names of the people she was talking to. But how about extensions of our empathic or  activist capabilities? What about a global-warming consciousness-raising implant, that reminded you of how much wasted energy is associated with each of the tasks you are considering? Or a thought monitor that measured the “neurosis quotient” of your internal monologue? Then, of course, comes the question of whether any of these enhancements are fair, appropriate, necessary, healthy, or even “moral.”

Don’t look for final answers on these pages. Instead, enjoy the opportunity to experience a bit of the kind of inquiry that engages the people who wrestle with these problems every day. They consider everything from how we anthropomorphize our machines to the unintended consequences of new technologies. Will machines allow us to build bigger conceptual taxonomies, or will they simply require us to learn how to trust them to think for us? Will humans have any time to think at all when they’re so busy building, repairing, and investing in thinking machines? And what if our machines learn what we teach them, rather than what it is we’d really like them to know? Will they force us to quit smoking cigarettes and eating partially hydrogenated vegetable oil? Will they conclude that the greenhouse effect is a danger worth forcing us to face, or a terrific way to get rid of those troublesome biped mammals, once and for all?

Most of us are not used to thinking this way, except when reading Isaac Asimov or Fritjof Capra. And then it’s from within the safely sealed context of science fiction or quantum thought experiments. The men and women who conducted the following discussions in Tarrytown, 2000, are doing this work for real, 24/7.

Maybe that’s why the most valuable lesson for us to take from this series of conversations is that in the very act of pondering the ways things could learn to learn, these scientists give us a window into how we might learn a thing or two, ourselves.